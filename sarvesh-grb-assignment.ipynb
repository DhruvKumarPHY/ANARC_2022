{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T16:24:00.511980Z","iopub.execute_input":"2023-09-14T16:24:00.512556Z","iopub.status.idle":"2023-09-14T16:24:00.528592Z","shell.execute_reply.started":"2023-09-14T16:24:00.512511Z","shell.execute_reply":"2023-09-14T16:24:00.527549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sarvesh-assignment/flux_plain.dat', sep='\\t',skiprows=18)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.622819Z","iopub.execute_input":"2023-09-14T16:24:00.624790Z","iopub.status.idle":"2023-09-14T16:24:00.655326Z","shell.execute_reply.started":"2023-09-14T16:24:00.624714Z","shell.execute_reply":"2023-09-14T16:24:00.654001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('flux plain.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.657409Z","iopub.execute_input":"2023-09-14T16:24:00.657844Z","iopub.status.idle":"2023-09-14T16:24:00.670520Z","shell.execute_reply.started":"2023-09-14T16:24:00.657808Z","shell.execute_reply":"2023-09-14T16:24:00.669185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/working/flux plain.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.734932Z","iopub.execute_input":"2023-09-14T16:24:00.735473Z","iopub.status.idle":"2023-09-14T16:24:00.762722Z","shell.execute_reply.started":"2023-09-14T16:24:00.735429Z","shell.execute_reply":"2023-09-14T16:24:00.761407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.764944Z","iopub.execute_input":"2023-09-14T16:24:00.765402Z","iopub.status.idle":"2023-09-14T16:24:00.773934Z","shell.execute_reply.started":"2023-09-14T16:24:00.765356Z","shell.execute_reply":"2023-09-14T16:24:00.772531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.776467Z","iopub.execute_input":"2023-09-14T16:24:00.777283Z","iopub.status.idle":"2023-09-14T16:24:00.803373Z","shell.execute_reply.started":"2023-09-14T16:24:00.777222Z","shell.execute_reply":"2023-09-14T16:24:00.801851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.head(284)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.862225Z","iopub.execute_input":"2023-09-14T16:24:00.862759Z","iopub.status.idle":"2023-09-14T16:24:00.882706Z","shell.execute_reply.started":"2023-09-14T16:24:00.862722Z","shell.execute_reply":"2023-09-14T16:24:00.881124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming your DataFrame columns have spaces in the column names, remove the extra spaces.\ndata.rename(columns={'Flux    ': 'Flux', '!Time    ': 'Time', 'T_+ve   ':'T_+ve','T_-ve   ':'T_-ve','Fluxpos ':'Fluxpos'}, inplace=True)\n\n# Convert the 'Flux' and 'Time' columns to float\ndata['Flux'] = pd.to_numeric(data['Flux'], errors='coerce')  # 'coerce' to handle non-numeric values\ndata['Time'] = pd.to_numeric(data['Time'], errors='coerce')\ndata['T_+ve'] = pd.to_numeric(data['T_+ve'], errors='coerce')  # 'coerce' to handle non-numeric values\ndata['T_-ve'] = pd.to_numeric(data['T_-ve'], errors='coerce')\ndata['Fluxpos'] = pd.to_numeric(data['Fluxpos'], errors='coerce')  # 'coerce' to handle non-numeric values\ndata['Fluxneg'] = pd.to_numeric(data['Fluxneg'], errors='coerce')\ndata['Fluxneg'] = np.abs(data['Fluxneg'])/10**10","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.885593Z","iopub.execute_input":"2023-09-14T16:24:00.886449Z","iopub.status.idle":"2023-09-14T16:24:00.907852Z","shell.execute_reply.started":"2023-09-14T16:24:00.886399Z","shell.execute_reply":"2023-09-14T16:24:00.906734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,8))\n# Extract data\nx = data['Time']\ny = data['Flux']\nx_err = [np.abs(data['T_-ve']), data['T_+ve']]\ny_err = [data['Fluxpos'],data['Fluxneg']]\n\n# Create a scatter plot with error bars\nplt.errorbar(x, y, xerr=x_err, yerr=y_err, fmt='o', markersize=5, color='red', ecolor='green', capsize=3)\n\n# Set x-axis and y-axis to logarithmic scale\nplt.xscale('log')\nplt.yscale('log')\n\n# Label axes and add a title\nplt.xlabel('Time')\nplt.ylabel('Flux')\nplt.title('Flux vs Time with Error Bars (log-log scale)')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:00.909729Z","iopub.execute_input":"2023-09-14T16:24:00.910125Z","iopub.status.idle":"2023-09-14T16:24:01.850463Z","shell.execute_reply.started":"2023-09-14T16:24:00.910090Z","shell.execute_reply":"2023-09-14T16:24:01.849241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:01.851661Z","iopub.execute_input":"2023-09-14T16:24:01.852001Z","iopub.status.idle":"2023-09-14T16:24:01.867866Z","shell.execute_reply.started":"2023-09-14T16:24:01.851974Z","shell.execute_reply":"2023-09-14T16:24:01.866482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:01.871008Z","iopub.execute_input":"2023-09-14T16:24:01.871386Z","iopub.status.idle":"2023-09-14T16:24:01.884370Z","shell.execute_reply.started":"2023-09-14T16:24:01.871349Z","shell.execute_reply":"2023-09-14T16:24:01.883165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# bidirection lstm Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\ndata = data.dropna()\n# Check for missing or NaN values in your data\nif data.isnull().values.any():\n    raise ValueError(\"Data contains missing or NaN values.\")\n\n# Assuming 'data' contains your dataset\n# X should contain all columns except 'Flux'\nX = data.drop('Flux', axis=1).values.astype(np.float32)\n\n# Use 'Flux' column as y\ny = data[\"Flux\"].values.astype(np.float32)\n\n# Check if y contains any NaN values\nif np.isnan(y).any():\n    raise ValueError(\"Target values 'y' contain NaN values.\")\n\n# Normalize input data to the range [0, 1]\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)\n\n# Reshape the input data to have a sequence dimension\n# Assuming you have only one feature per time step\nX = X.reshape(X.shape[0], X.shape[1], 1)  # Reshape to match the input shape (samples, time steps, features)\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define and train the Bidirectional LSTM model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.2), input_shape=(X.shape[1], 1)),\n    tf.keras.layers.Dense(1)\n])\n\n# Reduce learning rate and add gradient clipping to avoid NaN\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.0)\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\n\n# Add early stopping to monitor validation loss and prevent overfitting\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Print model summary for debugging\nmodel.summary()\n\n# Train the model and monitor progress\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n\n# Predict values\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:01.887553Z","iopub.execute_input":"2023-09-14T16:24:01.888045Z","iopub.status.idle":"2023-09-14T16:24:10.752991Z","shell.execute_reply.started":"2023-09-14T16:24:01.887998Z","shell.execute_reply":"2023-09-14T16:24:10.751781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:10.756793Z","iopub.execute_input":"2023-09-14T16:24:10.757153Z","iopub.status.idle":"2023-09-14T16:24:10.769762Z","shell.execute_reply.started":"2023-09-14T16:24:10.757123Z","shell.execute_reply":"2023-09-14T16:24:10.768411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:10.771405Z","iopub.execute_input":"2023-09-14T16:24:10.771812Z","iopub.status.idle":"2023-09-14T16:24:10.792095Z","shell.execute_reply.started":"2023-09-14T16:24:10.771764Z","shell.execute_reply":"2023-09-14T16:24:10.790802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_x = model.predict(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:10.793706Z","iopub.execute_input":"2023-09-14T16:24:10.794414Z","iopub.status.idle":"2023-09-14T16:24:10.904692Z","shell.execute_reply.started":"2023-09-14T16:24:10.794378Z","shell.execute_reply":"2023-09-14T16:24:10.903581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:10.906713Z","iopub.execute_input":"2023-09-14T16:24:10.907072Z","iopub.status.idle":"2023-09-14T16:24:10.915142Z","shell.execute_reply.started":"2023-09-14T16:24:10.907040Z","shell.execute_reply":"2023-09-14T16:24:10.914037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,8))\n# Extract data\ndata = data.dropna()\nx = data['Time']\ny = y_pred.reshape(-1)[:282]\n#x_err = [np.abs(data['T_-ve']), data['T_+ve']]\n#y_err = [data['Fluxpos'],data['Fluxneg']]\n\n# Create a scatter plot with error bars\n#plt.errorbar(x, y, xerr=x_err, yerr=y_err, fmt='o', markersize=5, color='red', ecolor='green', capsize=3)\nplt.scatter(x,y,color='red',marker='.',s=10)\n# Set x-axis and y-axis to logarithmic scale\nplt.xscale('log')\nplt.yscale('log')\n\n# Label axes and add a title\nplt.xlabel('Time')\nplt.ylabel('Flux')\nplt.title('Flux vs Time with Error Bars (log-log scale)')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:42.594357Z","iopub.execute_input":"2023-09-14T16:24:42.595791Z","iopub.status.idle":"2023-09-14T16:24:43.548892Z","shell.execute_reply.started":"2023-09-14T16:24:42.595731Z","shell.execute_reply":"2023-09-14T16:24:43.547557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:46.253470Z","iopub.execute_input":"2023-09-14T16:24:46.254080Z","iopub.status.idle":"2023-09-14T16:24:46.262854Z","shell.execute_reply.started":"2023-09-14T16:24:46.254029Z","shell.execute_reply":"2023-09-14T16:24:46.261419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:46.431723Z","iopub.execute_input":"2023-09-14T16:24:46.432644Z","iopub.status.idle":"2023-09-14T16:24:46.440635Z","shell.execute_reply.started":"2023-09-14T16:24:46.432595Z","shell.execute_reply":"2023-09-14T16:24:46.439474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# As I am not familier with the bidirection lstm model i am trying out some other methods and models top get my predictions right on point.","metadata":{}},{"cell_type":"code","source":"x = data.drop('Flux', axis=1)\ny = data['Flux']\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:46.611402Z","iopub.execute_input":"2023-09-14T16:24:46.611868Z","iopub.status.idle":"2023-09-14T16:24:46.621829Z","shell.execute_reply.started":"2023-09-14T16:24:46.611834Z","shell.execute_reply":"2023-09-14T16:24:46.620552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:46.778286Z","iopub.execute_input":"2023-09-14T16:24:46.778746Z","iopub.status.idle":"2023-09-14T16:24:46.821587Z","shell.execute_reply.started":"2023-09-14T16:24:46.778710Z","shell.execute_reply":"2023-09-14T16:24:46.820500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o_frame = h2o.H2OFrame(data)\nx = h2o_frame.columns\ny = 'Flux'\nx.remove(y)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:46.944124Z","iopub.execute_input":"2023-09-14T16:24:46.944546Z","iopub.status.idle":"2023-09-14T16:24:47.209622Z","shell.execute_reply.started":"2023-09-14T16:24:46.944513Z","shell.execute_reply":"2023-09-14T16:24:47.208371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o_automl = H2OAutoML(sort_metric='mse', max_runtime_secs=7*60, seed=42)\nh2o_automl.train(x=x, y=y, training_frame=h2o_frame)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:47.211665Z","iopub.execute_input":"2023-09-14T16:24:47.213442Z","iopub.status.idle":"2023-09-14T16:31:50.680680Z","shell.execute_reply.started":"2023-09-14T16:24:47.213395Z","shell.execute_reply":"2023-09-14T16:31:50.679540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o_models = h2o.automl.get_leaderboard(h2o_automl, extra_columns = \"ALL\")\nh2o_models","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:31:50.682437Z","iopub.execute_input":"2023-09-14T16:31:50.682766Z","iopub.status.idle":"2023-09-14T16:31:52.996899Z","shell.execute_reply.started":"2023-09-14T16:31:50.682738Z","shell.execute_reply":"2023-09-14T16:31:52.995712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from h2o.model.regression import h2o_mean_squared_error\n\nh2o_frame_test = h2o.H2OFrame(data)\n\ny_pred = h2o_automl.predict(h2o_frame_test)\ny_actual = h2o.H2OFrame(data[['Flux']])\n\nh2o_mean_squared_error(y_actual, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:11.348243Z","iopub.status.idle":"2023-09-14T16:24:11.348709Z","shell.execute_reply.started":"2023-09-14T16:24:11.348486Z","shell.execute_reply":"2023-09-14T16:24:11.348512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:11.350695Z","iopub.status.idle":"2023-09-14T16:24:11.351110Z","shell.execute_reply.started":"2023-09-14T16:24:11.350912Z","shell.execute_reply":"2023-09-14T16:24:11.350931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_actual","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:11.352816Z","iopub.status.idle":"2023-09-14T16:24:11.353260Z","shell.execute_reply.started":"2023-09-14T16:24:11.353061Z","shell.execute_reply":"2023-09-14T16:24:11.353081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert H2O frames to NumPy arrays\ny_pred_np = h2o.as_list(y_pred)\ny_actual_np = h2o.as_list(y_actual)\nplt.scatter(y_actual_np, y_pred_np, alpha=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:11.354722Z","iopub.status.idle":"2023-09-14T16:24:11.355598Z","shell.execute_reply.started":"2023-09-14T16:24:11.355380Z","shell.execute_reply":"2023-09-14T16:24:11.355401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,8))\n# Extract data\ndata = data.dropna()\nx = data['Time']\ny = y_pred_np\n#x_err = [np.abs(data['T_-ve']), data['T_+ve']]\n#y_err = [data['Fluxpos'],data['Fluxneg']]\n\n# Create a scatter plot with error bars\n#plt.errorbar(x, y, xerr=x_err, yerr=y_err, fmt='o', markersize=5, color='red', ecolor='green', capsize=3)\nplt.scatter(x,y,color='red',marker='.',s=10)\n# Set x-axis and y-axis to logarithmic scale\nplt.xscale('log')\nplt.yscale('log')\n\n# Label axes and add a title\nplt.xlabel('Time')\nplt.ylabel('Flux')\nplt.title('Flux vs Time with Error Bars (log-log scale)')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:24:11.357483Z","iopub.status.idle":"2023-09-14T16:24:11.358156Z","shell.execute_reply.started":"2023-09-14T16:24:11.357934Z","shell.execute_reply":"2023-09-14T16:24:11.357955Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}